{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c61d3a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7367b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Que1\n",
    "def dataMatrix(n, f):\n",
    "    return np.random.rand(n,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "278adeaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.45811646e-02, 7.21253409e-01, 1.03696413e-01, 9.72961191e-01,\n",
       "        3.64454426e-01],\n",
       "       [8.95839788e-01, 5.53854962e-02, 8.21296845e-01, 5.74137590e-01,\n",
       "        8.56229306e-01],\n",
       "       [9.67871455e-01, 1.64125813e-01, 8.45843851e-01, 6.01259326e-01,\n",
       "        2.19647327e-02],\n",
       "       [2.72742694e-01, 3.24512114e-01, 7.40066433e-01, 6.89664931e-01,\n",
       "        3.64920936e-04],\n",
       "       [5.61981802e-01, 3.46793943e-01, 4.67718722e-01, 1.17730216e-01,\n",
       "        5.73998335e-01]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataMatrix(5, 5)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a3662ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Que2\n",
    "def output(X, W, W0, var):\n",
    "    a = np.dot(X, W)\n",
    "    a = a.sum(axis = 1)\n",
    "    #print(a)\n",
    "    #print(a + W0)\n",
    "    return a + W0 + var\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a63f938",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.random.rand(5, 1)\n",
    "W0 = np.random.rand(1,1)\n",
    "var = np.random.rand(1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4613f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = output(X, W , W0, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48bbb70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.8198382 , 2.46216791, 1.53054234, 1.43050189, 1.73492988]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8b8c1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Que3\n",
    "def linearRegressionEstimate(X, w):\n",
    "    y = np.dot(X, w)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a469696e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.61025095],\n",
       "       [1.15509794],\n",
       "       [0.44146231],\n",
       "       [0.40692667],\n",
       "       [0.71652213]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearRegressionEstimate(X, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d1722bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Que4\n",
    "def meanSquareError(y, t):\n",
    "    mse = np.mean((y - t) ** 2)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "613a17ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7367145162889919"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.random.rand(1, 5)\n",
    "meanSquareError(Y, t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0785a657",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Que5\n",
    "def linearRegressionWeights(X, t, lamda):\n",
    "    X_reg = X.T.dot(X)\n",
    "    X_reg = X_reg + lamda * np.eye(X.shape[0])\n",
    "    X_pinv = np.linalg.pinv(X_reg)\n",
    "    w = np.dot(X_pinv, t.T)\n",
    "    y = X.dot(w)\n",
    "    mse = meanSquareError(y, t)\n",
    "    return w, mse, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fac19555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.0753706 ],\n",
       "        [ 0.09926943],\n",
       "        [ 0.08320693],\n",
       "        [ 0.07161375],\n",
       "        [ 0.17143244]]),\n",
       " 0.2357531712450736,\n",
       " array([[0.20902328],\n",
       "        [0.19421732],\n",
       "        [0.0605476 ],\n",
       "        [0.12268806],\n",
       "        [0.13781961]]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearRegressionWeights(X, t, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7bbe051",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Que6\n",
    "def gradientMSE(X, t, w):\n",
    "    y = linearRegressionEstimate(X, w)\n",
    "    err = y - t\n",
    "    gradient = 2 * np.dot(X.T, err) / X.shape[0]\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ece2e486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.6621422 ,  0.19016873,  0.10194487,  0.06937266, -0.11747068],\n",
       "       [ 0.30113909,  0.02376033, -0.02808883, -0.04723152, -0.15703933],\n",
       "       [ 0.65769071,  0.14517812,  0.04937647,  0.01400654, -0.18888529],\n",
       "       [ 0.60513679,  0.09655913,  0.001493  , -0.03360536, -0.23493945],\n",
       "       [ 0.56093186,  0.24829021,  0.18984952,  0.16827325,  0.04450568]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradientMSE(X, t, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae31c76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Que7\n",
    "def l2Norm(w):\n",
    "    norm2 = np.linalg.norm(w, ord=2) #Order 2 L2 normalization\n",
    "    return norm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b7ff0a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01758252]\n",
      " [0.077122  ]\n",
      " [0.31851735]\n",
      " [0.20453109]\n",
      " [0.8829984 ]]\n",
      "0.9639654494450257\n"
     ]
    }
   ],
   "source": [
    "print(W)\n",
    "print(l2Norm(W))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f0242e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Que8\n",
    "def gradientL2Nnorm(w):\n",
    "    gradient = np.zeros(w.shape)\n",
    "    gradient = w / np.linalg.norm(w, ord=2)\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d7db814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01823978],\n",
       "       [0.08000495],\n",
       "       [0.33042403],\n",
       "       [0.21217678],\n",
       "       [0.91600627]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradientL2Nnorm(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e63c2005",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Que9\n",
    "def l1Norm(w):\n",
    "    norm1 = np.linalg.norm(w, ord=1) #Order 1 L1 normalization\n",
    "    return norm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b3199fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5007513556472278\n"
     ]
    }
   ],
   "source": [
    "print(l1Norm(W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5a64c3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Que10\n",
    "def gradientL1Nnorm(w):\n",
    "    gradient = np.zeros(w.shape)\n",
    "    gradient = w / np.linalg.norm(w, ord=1)\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e28c9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Que11\n",
    "def update_weights_linear_regression(X, t, w, eta, lambda2, lambda1):\n",
    "    y = linearRegressionEstimate(X, w)\n",
    "    mse = 0.5*meanSquareError(y, t)\n",
    "    error = (y - t)# + lambda2*w + lambda1*np.sign(w)\n",
    "    gradient = X.T.dot(error) / X.shape[0]\n",
    "    #weights -= eta * gradient\n",
    "    #gradient = (np.dot(X.T + lambda2*w + lambda1*np.sign(w), (y-t)))/(X.shape[0])\n",
    "    w = w - (eta*gradient)\n",
    "    return w, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "92dcb4a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.01552459,  0.00807408,  0.01248528,  0.01411389,  0.02345605],\n",
       "        [ 0.06206505,  0.07593399,  0.07852645,  0.07948358,  0.08497397],\n",
       "        [ 0.28563281,  0.31125844,  0.31604852,  0.31781702,  0.32796161],\n",
       "        [ 0.17427425,  0.19970313,  0.20445644,  0.20621136,  0.21627806],\n",
       "        [ 0.85495181,  0.87058389,  0.87350592,  0.87458474,  0.88077312]]),\n",
       " 0.06953618283930918)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_weights_linear_regression(X, t, W, 0.1, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c6689c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e00f6ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#t_train"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d35a5c13",
   "metadata": {},
   "source": [
    "t_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "67ad1467",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Que12\n",
    "def gradient_descent(X, y, lambda2 = 0, lambda1 = 0, eta = 0.01, max_iter = 100, min_change_NRMSE = 0.000000000000000000000001):\n",
    "    #w = np.random.randn(X.shape[0])\n",
    "    prev_nrmse = 100\n",
    "    #for i in range(max_iter):\n",
    "        #print(i)\n",
    "        #print(w)\n",
    "        #w = w.T\n",
    "        #w, mse = update_weights_linear_regression(X, t, w, eta, lambda2, lambda1)\n",
    "        #nrmse = np.sqrt(mse)/(np.max(t) - np.min(t))\n",
    "        #if abs(prev_nrmse - nrmse) < min_change_NRMSE:\n",
    "        #    break\n",
    "        #prev_nrmse = nrmse\n",
    "    m, n = X.shape\n",
    "    weights = np.zeros(n)\n",
    "    #print(weights)\n",
    "    for i in range(max_iter):\n",
    "        y_pred = X.dot(weights)\n",
    "        error = (y_pred - y)# + lambda2*weights + lambda1*np.sign(weights)\n",
    "        gradient = X.T.dot(error) / m\n",
    "        weights -= eta * gradient\n",
    "        mse = meanSquareError(y, y_pred)\n",
    "        #w, mse = update_weights_linear_regression(X, t, weights, eta, lambda2, lambda1)\n",
    "        nrmse = np.sqrt(mse)/(np.max(t) - np.min(t))\n",
    "        if abs(prev_nrmse - nrmse) < min_change_NRMSE:\n",
    "            break\n",
    "        prev_nrmse = nrmse\n",
    "    return weights, prev_nrmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c8e16e2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m gradient_descent(\u001b[43mX_train\u001b[49m, t_train, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m10000\u001b[39m, \u001b[38;5;241m0.000000000000000000001\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "gradient_descent(X_train, t_train, 0, 0, 0.1, 10000, 0.000000000000000000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6616f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Que 13 started\n",
    "\n",
    "def generateData(num_samples, var):\n",
    "    X_train = dataMatrix(num_samples, var)\n",
    "    t_train = X_train.dot(np.random.randn(var)) + np.random.randn(num_samples)\n",
    "    X_val = dataMatrix(num_samples, var)\n",
    "    t_val = X_val.dot(np.random.randn(var)) + np.random.randn(num_samples)\n",
    "    return X_train, X_val, t_train, t_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7066e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pseudoInverseRegression(X_train, t_train, X_val, t_val, alpha = 0, noise_var = 0, w0 = 0):\n",
    "    #X_train = np.dot(X_train.T, X_train)\n",
    "    #t_train = np.dot(t_train.T, t_train)\n",
    "    X1 = np.linalg.pinv(np.dot(X_train.T, X_train)+ alpha * np.eye(X_train.shape[1]) + noise_var * np.eye(X_train.shape[1]))\n",
    "    #print(np.shape(a))\n",
    "    #X_dagger = np.linalg.pinv(np.dot(X_train, X_train.T) + alpha * np.eye(X_train.shape[0]) + noise_var * np.eye(X_train.shape[0]))\n",
    "    X2 = np.dot(X1, X_train.T)\n",
    "\n",
    "    # Calculate the regression coefficients\n",
    "    #print(t_train)\n",
    "    \n",
    "    w = np.dot(X2, (t_train-w0))\n",
    "    \n",
    "   \n",
    "    \n",
    "    #X_train = alpha + noise_var * X_train\n",
    "    #w = np.linalg.pinv(X_train).dot(t_train)\n",
    "    #print(w)\n",
    "    t_train_pred = X_train.dot(w)\n",
    "    t_val_pred = X_val.dot(w)\n",
    "    train_nrmse = np.sqrt(np.mean((t_train - t_train_pred)**2)) / np.std(t_train)\n",
    "    val_nrmse = np.sqrt(np.mean((t_val - t_val_pred)**2)) / np.std(t_val)\n",
    "    return train_nrmse, val_nrmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4053eae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_list = [10**x for x in range(1,7)]\n",
    "train_nrmse_list = []\n",
    "val_nrmse_list = []\n",
    "var = 5\n",
    "for num_samples in num_samples_list:\n",
    "    X_train, X_val, t_train, t_val = generateData(num_samples, var)\n",
    "    print(X_train)\n",
    "    train_nrmse,val_nrmse = pseudoInverseRegression(X_train, t_train, X_val, t_val, 0, 0)\n",
    "    train_nrmse_list.append(train_nrmse)\n",
    "    val_nrmse_list.append(val_nrmse)\n",
    "\n",
    "# I thought here that line plot looks better than line plot\n",
    "plt.plot(num_samples_list, train_nrmse_list, 'o-', label='Training NRMSE')\n",
    "plt.plot(num_samples_list, val_nrmse_list, 'o-', label='Validation NRMSE')\n",
    "plt.xlabel('Number of Training Samples')\n",
    "plt.ylabel('NRMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800d1240",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100\n",
    "train_nrmse_list = []\n",
    "val_nrmse_list = []\n",
    "var = [2*x for x in range(20)]\n",
    "for va in var:\n",
    "    X_train, X_val, t_train, t_val = generateData(num_samples, va)\n",
    "    train_nrmse,val_nrmse = pseudoInverseRegression(X_train, t_train, X_val, t_val)\n",
    "    train_nrmse_list.append(train_nrmse)\n",
    "    val_nrmse_list.append(val_nrmse)\n",
    "\n",
    "# I thought here that line plot looks better than line plot\n",
    "plt.plot(var, train_nrmse_list, 'o-', label='Training NRMSE')\n",
    "plt.plot(var, val_nrmse_list, 'o-', label='Validation NRMSE')\n",
    "plt.xlabel('Number of Variables')\n",
    "plt.ylabel('NRMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cbc466",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100\n",
    "train_nrmse_list = []\n",
    "val_nrmse_list = []\n",
    "noise_var_list = [0.5**x for x in range(10)]\n",
    "var = 5\n",
    "X_train, X_val, t_train, t_val = generateData(num_samples, var)\n",
    "for n_va in noise_var_list:\n",
    "    #X_train, X_val, t_train, t_val = generateData(num_samples, var)\n",
    "    train_nrmse,val_nrmse = pseudoInverseRegression(X_train, t_train, X_val, t_val, noise_var = n_va)\n",
    "    train_nrmse_list.append(train_nrmse)\n",
    "    val_nrmse_list.append(val_nrmse)\n",
    "print(train_nrmse_list)\n",
    "print('******')\n",
    "print(val_nrmse_list)\n",
    "# I thought here that line plot looks better than line plot\n",
    "plt.plot(noise_var_list, train_nrmse_list, 'o-', label='Training NRMSE')\n",
    "plt.plot(noise_var_list, val_nrmse_list, 'o-', label='Validation NRMSE')\n",
    "plt.xlabel('noise_var_list')\n",
    "plt.ylabel('NRMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a573ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100\n",
    "train_nrmse_list = []\n",
    "val_nrmse_list = []\n",
    "W0 = [0.5**x for x in range(10)]\n",
    "var = 5\n",
    "X_train, X_val, t_train, t_val = generateData(num_samples, var)\n",
    "for w0 in W0:\n",
    "    #X_train, X_val, t_train, t_val = generateData(num_samples, var)\n",
    "    train_nrmse,val_nrmse = pseudoInverseRegression(X_train, t_train, X_val, t_val, w0 = w0)\n",
    "    train_nrmse_list.append(train_nrmse)\n",
    "    val_nrmse_list.append(val_nrmse)\n",
    "print(train_nrmse_list)\n",
    "print('******')\n",
    "print(val_nrmse_list)\n",
    "# I thought here that line plot looks better than line plot\n",
    "plt.plot(W0, train_nrmse_list, 'o-', label='Training NRMSE')\n",
    "plt.plot(W0, val_nrmse_list, 'o-', label='Validation NRMSE')\n",
    "plt.xlabel('W0')\n",
    "plt.ylabel('NRMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be760de",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100\n",
    "train_nrmse_list = []\n",
    "val_nrmse_list = []\n",
    "alpha_list = [1*x for x in range(10)]\n",
    "var = 5\n",
    "X_train, X_val, t_train, t_val = generateData(num_samples, var)\n",
    "for alpha_L in alpha_list:\n",
    "    #X_train, X_val, t_train, t_val = generateData(num_samples, var)\n",
    "    train_nrmse,val_nrmse = pseudoInverseRegression(X_train, t_train, X_val, t_val, alpha = alpha_L)\n",
    "    train_nrmse_list.append(train_nrmse)\n",
    "    val_nrmse_list.append(val_nrmse)\n",
    "print(train_nrmse_list)\n",
    "print('******')\n",
    "print(val_nrmse_list)\n",
    "# I thought here that line plot looks better than line plot\n",
    "plt.plot(alpha_list, train_nrmse_list, 'o-', label='Training NRMSE')\n",
    "plt.plot(alpha_list, val_nrmse_list, 'o-', label='Validation NRMSE')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('NRMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8003d841",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_list = [10**x for x in range(1,5)]\n",
    "num_samples1 = []\n",
    "time1 = []\n",
    "var = 5\n",
    "for num_samples in num_samples_list:\n",
    "    print('num_samples')\n",
    "    print(num_samples)\n",
    "    st = time.time()\n",
    "    X_train, X_val, t_train, t_val = generateData(num_samples, var)\n",
    "    #print(X_train)\n",
    "    train_nrmse,val_nrmse = pseudoInverseRegression(X_train, t_train, X_val, t_val, 0, 0)\n",
    "    et = time.time()\n",
    "    print('time')\n",
    "    print(et-st)\n",
    "    num_samples1.append(num_samples)\n",
    "    time1.append(et-st)\n",
    "\n",
    "# I thought here that line plot looks better than line plot\n",
    "plt.plot(num_samples1, time1, 'o-', label='Training NRMSE')\n",
    "#plt.plot(num_samples_list, val_nrmse_list, 'o-', label='Validation NRMSE')\n",
    "plt.xlabel('Number of Training Samples')\n",
    "plt.ylabel('NRMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db73c7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "train_nrmse_list = []\n",
    "val_nrmse_list = []\n",
    "max_iterations = [10**x for x in range(1, 6)]\n",
    "var = 5\n",
    "X_train, X_val, t_train, t_val = generateData(num_samples, var)\n",
    "for max_iteration in max_iterations:\n",
    "    #X_train, X_val, t_train, t_val = generateData(num_samples, var)\n",
    "    weights, train_nrmse = gradient_descent(X_train, t_train, lambda2 = 0, lambda1 = 0, eta = 0.01, max_iter = max_iteration, min_change_NRMSE = 0.000000000000000000000001)\n",
    "    y_val = linearRegressionEstimate(X_val, weights)\n",
    "    val_nrmse = np.sqrt(np.mean((t_val - y_val)**2)) / np.std(t_val)\n",
    "    print(y_val)\n",
    "    #train_nrmse,val_nrmse = pseudoInverseRegression(X_train, t_train, X_val, t_val, alpha = alpha_L)\n",
    "    train_nrmse_list.append(train_nrmse)\n",
    "    val_nrmse_list.append(val_nrmse)\n",
    "print(train_nrmse_list)\n",
    "print('******')\n",
    "print(val_nrmse_list)\n",
    "# I thought here that line plot looks better than line plot\n",
    "plt.plot(max_iterations, train_nrmse_list, 'o-', label='Training NRMSE')\n",
    "plt.plot(max_iterations, val_nrmse_list, 'o-', label='Validation NRMSE')\n",
    "plt.xlabel('max_iterations')\n",
    "plt.ylabel('NRMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f898b6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "train_nrmse_list = []\n",
    "val_nrmse_list = []\n",
    "etaa_list = [0.5**x for x in range(1, 10)]\n",
    "var = 5\n",
    "X_train, X_val, t_train, t_val = generateData(num_samples, var)\n",
    "for etaa in etaa_list:\n",
    "    #X_train, X_val, t_train, t_val = generateData(num_samples, var)\n",
    "    weights, train_nrmse = gradient_descent(X_train, t_train, lambda2 = 0, lambda1 = 0, eta = etaa, max_iter = 1000, min_change_NRMSE = 0.000000000000000000000001)\n",
    "    y_val = linearRegressionEstimate(X_val, weights)\n",
    "    val_nrmse = np.sqrt(np.mean((t_val - y_val)**2)) / np.std(t_val)\n",
    "    print(y_val)\n",
    "    #train_nrmse,val_nrmse = pseudoInverseRegression(X_train, t_train, X_val, t_val, alpha = alpha_L)\n",
    "    train_nrmse_list.append(train_nrmse)\n",
    "    val_nrmse_list.append(val_nrmse)\n",
    "#print(train_nrmse_list)\n",
    "#print('******')\n",
    "#print(val_nrmse_list)\n",
    "# I thought here that line plot looks better than line plot\n",
    "plt.plot(etaa_list, train_nrmse_list, 'o-', label='Training NRMSE')\n",
    "plt.plot(etaa_list, val_nrmse_list, 'o-', label='Validation NRMSE')\n",
    "plt.xlabel('eta')\n",
    "plt.ylabel('NRMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cab6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = [10**x for x in range(1, 5)]\n",
    "train_nrmse_list = []\n",
    "val_nrmse_list = []\n",
    "#etaa_list = [0.5**x for x in range(1, 10)]\n",
    "var = [5*x for x in range(1, 10)]\n",
    "\n",
    "for sample in num_samples:\n",
    "    for va in var:\n",
    "        X_train, X_val, t_train, t_val = generateData(sample, va)\n",
    "        st = time.time()\n",
    "        \n",
    "        #X_train, X_val, t_train, t_val = generateData(num_samples, var)\n",
    "        weights, train_nrmse = gradient_descent(X_train, t_train, lambda2 = 0, lambda1 = 0, eta = 0.01, max_iter = 1000, min_change_NRMSE = 0.000000000000000000000001)\n",
    "        y_val = linearRegressionEstimate(X_val, weights)\n",
    "        val_nrmse = np.sqrt(np.mean((t_val - y_val)**2)) / np.std(t_val)\n",
    "        ed = time.time()\n",
    "        print('num_samples = ', sample, 'variables = ', va, 'time = ', ed-st)\n",
    "        #print(y_val)\n",
    "        #train_nrmse,val_nrmse = pseudoInverseRegression(X_train, t_train, X_val, t_val, alpha = alpha_L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288a3e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "train_nrmse_list = []\n",
    "val_nrmse_list = []\n",
    "#etaa_list = [0.5**x for x in range(1, 10)]\n",
    "var = [5*x for x in range(1, 10)]\n",
    "\n",
    "\n",
    "for va in var:\n",
    "    X_train, X_val, t_train, t_val = generateData(sample, va)\n",
    "    st = time.time()\n",
    "\n",
    "    #X_train, X_val, t_train, t_val = generateData(num_samples, var)\n",
    "    weights, train_nrmse = gradient_descent(X_train, t_train, lambda2 = 0, lambda1 = 0, eta = 0.01, max_iter = 1000, min_change_NRMSE = 0.000000000000000000000001)\n",
    "    y_val = linearRegressionEstimate(X_val, weights)\n",
    "    val_nrmse = np.sqrt(np.mean((t_val - y_val)**2)) / np.std(t_val)\n",
    "    ed = time.time()\n",
    "    print('variables = ', va, 'time = ', ed-st)\n",
    "    #print(y_val)\n",
    "    #train_nrmse,val_nrmse = pseudoInverseRegression(X_train, t_train, X_val, t_val, alpha = alpha_L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5affa95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "train_nrmse_list = []\n",
    "val_nrmse_list = []\n",
    "#etaa_list = [0.5**x for x in range(1, 10)]\n",
    "lambda22 = [0.5*x for x in range(1, 10)]\n",
    "\n",
    "\n",
    "for lambd in lambda22:\n",
    "    X_train, X_val, t_train, t_val = generateData(sample, va)\n",
    "    #st = time.time()\n",
    "\n",
    "    #X_train, X_val, t_train, t_val = generateData(num_samples, var)\n",
    "    weights, train_nrmse = gradient_descent(X_train, t_train, lambda2 = lambd, lambda1 = 0, eta = 0.01, max_iter = 1000, min_change_NRMSE = 0.000000000000000000000001)\n",
    "    y_val = linearRegressionEstimate(X_val, weights)\n",
    "    val_nrmse = np.sqrt(np.mean((t_val - y_val)**2)) / np.std(t_val)\n",
    "    #ed = time.time()\n",
    "    print('lambda2 = ', lambd, 'weights = ', weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec34369",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 1000\n",
    "train_nrmse_list = []\n",
    "val_nrmse_list = []\n",
    "#etaa_list = [0.5**x for x in range(1, 10)]\n",
    "lambda11 = [0.5*x for x in range(1, 10)]\n",
    "\n",
    "\n",
    "for lambd in lambda11:\n",
    "    X_train, X_val, t_train, t_val = generateData(sample, va)\n",
    "    #st = time.time()\n",
    "\n",
    "    #X_train, X_val, t_train, t_val = generateData(num_samples, var)\n",
    "    weights, train_nrmse = gradient_descent(X_train, t_train, lambda2 = 0, lambda1 = lambd, eta = 0.01, max_iter = 1000, min_change_NRMSE = 0.000000000000000000000001)\n",
    "    y_val = linearRegressionEstimate(X_val, weights)\n",
    "    val_nrmse = np.sqrt(np.mean((t_val - y_val)**2)) / np.std(t_val)\n",
    "    #ed = time.time()\n",
    "    print('lambda1 = ', lambd, 'weights = ', weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a046c716",
   "metadata": {},
   "source": [
    "This assignment is helpful to gain knowledge of how regression works in python\n",
    "In this we use modstly two methods\n",
    "1) pseudo inverse method\n",
    "2) iteration method\n",
    "\n",
    "So in this I learn abour how maths work behind algorithems and how to impliment them with python code'\n",
    "also get insights about how time complexity works in this algorithems\n",
    "\n",
    "also understands ML is not only use skikit learn and apply models with two lines of code, its much more complex than that and how complex maths works behind algorithems which liooks simple to apply in skikit learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a16ec5b",
   "metadata": {},
   "source": [
    "Video link - https://drive.google.com/file/d/1zrCAEXrutRGi3Lm_RUqWLtER4rkqmFis/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c666e015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a889b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d613b2a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1383026a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
